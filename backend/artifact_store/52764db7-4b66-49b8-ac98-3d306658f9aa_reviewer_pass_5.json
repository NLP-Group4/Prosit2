{"files": [{"path": "app/main.py", "content": "from fastapi import FastAPI\nimport logging\nimport os\nimport uvicorn\n\nfrom app.routes import router as api_router\nfrom app.database import create_db_and_tables\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(\"app.main\")\n\ndef create_app() -> FastAPI:\n    app = FastAPI(\n        title=\"Calculus Calculator API\",\n        description=\"API for parsing and evaluating calculus-style mathematical expressions.\",\n        version=\"0.1.0\",\n    )\n\n    app.include_router(api_router)\n\n    @app.on_event(\"startup\")\n    def on_startup():\n        logger.info(\"Starting up: creating DB tables if needed...\")\n        try:\n            create_db_and_tables()\n            logger.info(\"Database tables are ensured.\")\n        except Exception as e:\n            logger.exception(\"Failed to create or verify database tables: %s\", e)\n            # Let startup proceed; errors will surface on DB operations.\n\n    return app\n\napp = create_app()\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", \"8000\"))\n    uvicorn.run(\"app.main:app\", host=\"0.0.0.0\", port=port)"}, {"path": "app/database.py", "content": "from typing import Generator, Optional\nimport os\nimport logging\n\nfrom sqlmodel import SQLModel, create_engine, Session\nfrom sqlalchemy.engine import Engine\n\nlogger = logging.getLogger(__name__)\n\n# Read database URL from env, default to a local SQLite file for convenience.\nDATABASE_URL = os.getenv(\"DATABASE_URL\", \"sqlite:///./calculations.db\")\n\n# For SQLite, allow check_same_thread flag for usage in different threads (typical for FastAPI)\nconnect_args = {\"check_same_thread\": False} if DATABASE_URL.startswith(\"sqlite\") else {}\n\n# Create the SQLModel engine\nengine: Engine = create_engine(DATABASE_URL, echo=False, connect_args=connect_args)\n\n\ndef get_session() -> Generator[Session, None, None]:\n    \"\"\"\n    FastAPI dependency that yields a SQLModel Session.\n    Usage:\n        from fastapi import Depends\n        from app.database import get_session\n        def endpoint(session: Session = Depends(get_session)): ...\n    \"\"\"\n    session = Session(engine)\n    try:\n        yield session\n    finally:\n        session.close()\n\n\ndef create_db_and_tables(target_engine: Optional[Engine] = None) -> None:\n    \"\"\"\n    Create database tables for all SQLModel models.\n\n    Parameters:\n        target_engine: Optional Engine to use. If not provided, uses module-level `engine`.\n    \"\"\"\n    eng = target_engine or engine\n    logger.info(\"Creating database tables (if not exist) using engine: %s\", eng)\n    SQLModel.metadata.create_all(eng)"}, {"path": "app/models.py", "content": "from __future__ import annotations\n\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import List, Optional\nfrom uuid import uuid4\n\nfrom sqlalchemy import Column, JSON, Enum as SAEnum, String, Text\nfrom sqlmodel import Field, SQLModel\n\n\nclass ResultType(str, Enum):\n    numeric = \"numeric\"\n    symbolic = \"symbolic\"\n    error = \"error\"\n\n\nclass AngleMode(str, Enum):\n    radians = \"radians\"\n    degrees = \"degrees\"\n\n\nclass Calculation(SQLModel, table=True):\n    __tablename__ = \"calculations\"\n\n    id: Optional[str] = Field(\n        default_factory=lambda: str(uuid4()),\n        primary_key=True,\n        index=True,\n        sa_column=Column(String(length=36)),\n    )\n\n    # Raw input expression from the client\n    expression: str = Field(sa_column=Column(Text), nullable=False)\n\n    # Normalized expression and/or tokenized AST; stored as JSON for flexibility\n    normalized_expression: Optional[dict] = Field(\n        default=None,\n        sa_column=Column(JSON),\n        description=\"Normalized expression or token/AST representation (JSON)\",\n    )\n\n    # Result stored as string for easy transport; numeric results also stored here\n    result: Optional[str] = Field(default=None, sa_column=Column(Text), nullable=True)\n\n    result_type: ResultType = Field(\n        sa_column=Column(SAEnum(ResultType), nullable=False), default=ResultType.numeric\n    )\n\n    error_message: Optional[str] = Field(\n        default=None, sa_column=Column(Text), nullable=True\n    )\n\n    precision: int = Field(default=6, nullable=False)\n\n    angle_mode: AngleMode = Field(\n        default=AngleMode.radians,\n        sa_column=Column(SAEnum(AngleMode)),\n        nullable=False,\n    )\n\n    # Steps stored as JSON array of strings (or structured steps)\n    steps: Optional[List[str]] = Field(default=None, sa_column=Column(JSON), description=\"Step-by-step reasoning or an empty value if not generated\")\n\n    # Timestamps\n    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)\n\n\nclass ExampleProblem(SQLModel, table=True):\n    __tablename__ = \"example_problems\"\n\n    id: Optional[str] = Field(\n        default_factory=lambda: str(uuid4()),\n        primary_key=True,\n        index=True,\n        sa_column=Column(String(length=36)),\n    )\n\n    title: str = Field(sa_column=Column(Text), nullable=False)\n    description: Optional[str] = Field(default=None, sa_column=Column(Text), nullable=True)\n    expression: str = Field(sa_column=Column(Text), nullable=False)\n    solution: Optional[str] = Field(default=None, sa_column=Column(Text), nullable=True)\n\n    # Steps can be an ordered list of step descriptions; stored as JSON\n    steps: Optional[List[str]] = Field(default=None, sa_column=Column(JSON), nullable=True)\n\n    # Tags stored as JSON array for cross-DB compatibility (Postgres could use ARRAY)\n    tags: Optional[List[str]] = Field(default=None, sa_column=Column(JSON), nullable=True)\n\n    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)\n\n\nclass UserPreference(SQLModel, table=True):\n    __tablename__ = \"user_preferences\"\n\n    # id represents client id or api-key identifier\n    id: Optional[str] = Field(\n        default_factory=lambda: str(uuid4()),\n        primary_key=True,\n        index=True,\n        sa_column=Column(String(length=36)),\n    )\n\n    default_precision: int = Field(default=6, nullable=False)\n    angle_mode: AngleMode = Field(\n        default=AngleMode.radians, sa_column=Column(SAEnum(AngleMode)), nullable=False\n    )\n    show_steps_by_default: bool = Field(default=False, nullable=False)\n    created_at: datetime = Field(default_factory=datetime.utcnow, index=True)"}, {"path": "app/schemas.py", "content": "from enum import Enum\nfrom typing import Any, Dict, List, Optional\n\nfrom datetime import datetime\nfrom pydantic import BaseModel, Field, validator\n\n\nMAX_EXPRESSION_LENGTH = 1000\nDEFAULT_PRECISION = 6\nMIN_PRECISION = 0\nMAX_PRECISION = 12\n\n\nclass AngleMode(str, Enum):\n    radians = \"radians\"\n    degrees = \"degrees\"\n\n\nclass ResultType(str, Enum):\n    numeric = \"numeric\"\n    symbolic = \"symbolic\"\n    error = \"error\"\n\n\nclass ErrorResponse(BaseModel):\n    error_code: str\n    message: str\n    details: Optional[Dict[str, Any]] = None\n\n\nclass ParseRequest(BaseModel):\n    expression: str = Field(..., description=\"Raw expression to be parsed/normalized\")\n\n    @validator(\"expression\")\n    def check_expression_length(cls, v: str) -> str:\n        if not isinstance(v, str) or not v.strip():\n            raise ValueError(\"expression must be a non-empty string\")\n        if len(v) > MAX_EXPRESSION_LENGTH:\n            raise ValueError(f\"expression exceeds max length of {MAX_EXPRESSION_LENGTH}\")\n        return v.strip()\n\n\nclass ParseResponse(BaseModel):\n    normalized_expression: str\n    # A safe AST or token list representation produced by the parser.\n    # Each node is represented by a dict (e.g., {\"type\": \"func\", \"name\": \"sin\", ...}) or similar.\n    ast: List[Dict[str, Any]] = Field(\n        default_factory=list, description=\"Safe AST / token list generated from the expression\"\n    )\n    warnings: Optional[List[str]] = None\n\n\nclass EvaluateRequest(BaseModel):\n    expression: str = Field(..., description=\"Expression to evaluate\")\n    precision: Optional[int] = Field(\n        DEFAULT_PRECISION, description=f\"Number of decimal places (between {MIN_PRECISION} and {MAX_PRECISION})\"\n    )\n    angle_mode: Optional[AngleMode] = Field(AngleMode.radians, description=\"Angle mode for trig functions\")\n    show_steps: Optional[bool] = Field(False, description=\"Whether to return/generate step-by-step reasoning\")\n    complex_mode: Optional[bool] = Field(False, description=\"Allow complex numbers in results\")\n    # Optional client identifier (e.g., API key owner); not required for core evaluation but useful for persistence\n    client_id: Optional[str] = None\n\n    @validator(\"expression\")\n    def validate_expression(cls, v: str) -> str:\n        if not isinstance(v, str) or not v.strip():\n            raise ValueError(\"expression must be a non-empty string\")\n        if len(v) > MAX_EXPRESSION_LENGTH:\n            raise ValueError(f\"expression exceeds max length of {MAX_EXPRESSION_LENGTH}\")\n        return v.strip()\n\n    @validator(\"precision\")\n    def validate_precision(cls, v: Optional[int]) -> Optional[int]:\n        if v is None:\n            return DEFAULT_PRECISION\n        if not (MIN_PRECISION <= v <= MAX_PRECISION):\n            raise ValueError(f\"precision must be between {MIN_PRECISION} and {MAX_PRECISION}\")\n        return v\n\n\nclass EvaluateResponse(BaseModel):\n    id: Optional[str] = Field(None, description=\"Calculation record id (if persisted)\")\n    result: Optional[str] = Field(None, description=\"Stringified result\")\n    result_type: ResultType = Field(..., description=\"Type of the returned result\")\n    normalized_expression: Optional[str] = None\n    steps: Optional[List[str]] = None\n    queued: Optional[bool] = Field(False, description=\"True if step-generation was queued for async processing\")\n    task_id: Optional[str] = Field(None, description=\"Task id if queued\")\n    error: Optional[ErrorResponse] = None\n    precision: Optional[int] = None\n    angle_mode: Optional[AngleMode] = None\n    created_at: Optional[datetime] = None\n\n\nclass FunctionInfo(BaseModel):\n    name: str\n    aliases: Optional[List[str]] = None\n    signature: Optional[str] = None\n    description: Optional[str] = None\n    domain_notes: Optional[str] = None\n    examples: Optional[List[str]] = None\n\n\nclass FunctionsResponse(BaseModel):\n    functions: List[FunctionInfo] = Field(default_factory=list)\n\n\nclass CalculationOut(BaseModel):\n    id: str\n    expression: str\n    normalized_expression: Optional[str] = None\n    result: Optional[str] = None\n    result_type: ResultType\n    error_message: Optional[str] = None\n    precision: Optional[int] = None\n    angle_mode: Optional[AngleMode] = None\n    steps: Optional[List[str]] = None\n    client_id: Optional[str] = None\n    created_at: datetime\n\n\nclass CalculationList(BaseModel):\n    total: int\n    limit: int\n    offset: int\n    items: List[CalculationOut] = Field(default_factory=list)\n\n\nclass ExampleOut(BaseModel):\n    id: str\n    title: str\n    description: Optional[str] = None\n    expression: str\n    solution: Optional[str] = None\n    steps: Optional[List[str]] = None\n    tags: Optional[List[str]] = None\n\n\nclass ExampleList(BaseModel):\n    total: int\n    limit: int\n    offset: int\n    items: List[ExampleOut] = Field(default_factory=list)\n\n\nclass HealthCheckDetail(BaseModel):\n    ok: bool\n    message: Optional[str] = None\n\n\nclass HealthResponse(BaseModel):\n    status: str\n    checks: Dict[str, HealthCheckDetail]\n\n\n# Minimal token schemas for auth flows (app/auth.py may use these)\nclass Token(BaseModel):\n    access_token: str\n    token_type: str = \"bearer\"\n\n\nclass TokenData(BaseModel):\n    client_id: Optional[str] = None\n    scopes: Optional[List[str]] = None"}, {"path": "app/services.py", "content": "from typing import Any, Dict, List, Optional, Tuple\nimport re\nimport math\nimport uuid\n\nfrom sympy import (\n    Symbol,\n    sympify,\n    SympifyError,\n    preorder_traversal,\n    Function,\n    pi,\n    Float,\n    I,\n)\nfrom sympy.parsing.sympy_parser import (\n    parse_expr,\n    standard_transformations,\n    implicit_multiplication_application,\n)\nfrom sympy.core import Expr, numbers, atoms\nfrom mpmath import mp\n\n# Exceptions used by services\nclass ParseError(Exception):\n    def __init__(self, message: str, details: Optional[Any] = None):\n        super().__init__(message)\n        self.message = message\n        self.details = details\n\n\nclass DomainError(Exception):\n    def __init__(self, message: str, error_type: str = \"domain_error\", details: Optional[Any] = None):\n        super().__init__(message)\n        self.message = message\n        self.error_type = error_type\n        self.details = details\n\n\nclass EvaluationError(Exception):\n    def __init__(self, message: str, details: Optional[Any] = None):\n        super().__init__(message)\n        self.message = message\n        self.details = details\n\n\n# Configuration defaults\nDEFAULT_MAX_INPUT_LENGTH = 1000\nDEFAULT_AST_DEPTH_LIMIT = 50\nDEFAULT_PRECISION = 6\nMAX_STEP_NODES = 120  # dont attempt steps for very large ASTs\n\n\n# Whitelist of allowed characters (basic safety)\n_ALLOWED_CHARS_RE = re.compile(r'^[0-9a-zA-Z\\s\\+\\-\\*\\/\\^\\.\\,\\(\\)\\[\\]\\{\\}=_]+$')\n\n# Mapping of supported functions to SymPy functions (string name -> sympy symbol/function)\n# Not all functions need to be mapped to actual sympy.Function objects here; parse_expr will resolve names\n_SUPPORTED_FUNCTIONS = {\n    \"sin\": \"sin\",\n    \"cos\": \"cos\",\n    \"tan\": \"tan\",\n    \"asin\": \"asin\",\n    \"acos\": \"acos\",\n    \"atan\": \"atan\",\n    \"sinh\": \"sinh\",\n    \"cosh\": \"cosh\",\n    \"exp\": \"exp\",\n    \"ln\": \"log\",  # alias\n    \"log\": \"log\",\n    \"sqrt\": \"sqrt\",\n    \"abs\": \"Abs\",\n    \"fabs\": \"Abs\",\n    # add more as needed\n}\n\n# Domain check descriptors for some functions\n_FUNCTION_DOMAIN_NOTES = {\n    \"sqrt\": \"Argument must be non-negative when complex_mode is disabled.\",\n    \"log\": \"Argument must be positive for real logarithm. Use log(x, base) for specific bases.\",\n    \"ln\": \"Alias of log.\",\n    \"asin\": \"Argument must be in [-1, 1] for real output.\",\n    \"acos\": \"Argument must be in [-1, 1] for real output.\",\n    \"atan\": \"All real numbers allowed.\",\n    \"sin\": \"All real numbers allowed.\",\n    \"cos\": \"All real numbers allowed.\",\n    \"tan\": \"All real numbers allowed; watch for poles where cos(x) = 0.\",\n}\n\n\ndef _build_local_dict():\n    \"\"\"\n    Prepare local dict for parse_expr that maps allowed names to sympy functions/symbols.\n    \"\"\"\n    local = {}\n    # Import symbols from sympy by name where appropriate\n    # Use sympify for function names to resolve SymPy functions like sin, cos, log\n    for name, target in _SUPPORTED_FUNCTIONS.items():\n        try:\n            local[name] = sympify(target)\n        except Exception:\n            # fall back to name - parse_expr will raise if invalid\n            local[name] = Symbol(name)\n    # allow common constants\n    local[\"pi\"] = pi\n    local[\"e\"] = sympify(\"E\")\n    return local\n\n\nLOCAL_DICT = _build_local_dict()\nTRANSFORMATIONS = standard_transformations + (implicit_multiplication_application,)\n\n\ndef _check_allowed_chars(expr: str):\n    \"\"\"\n    Validate the input expression's characters and screen for suspicious substrings/patterns.\n\n    Enhanced checks:\n    - Only allow a conservative set of characters (letters, digits, whitespace, basic operators, parentheses, commas, periods, underscores, braces/brackets).\n    - Reject potentially dangerous substrings like 'import', 'os.', 'sys.', 'eval(', 'exec(', 'open(', backticks, semicolons, pipes, etc.\n    - Reject double-underscore patterns (e.g., '__') which could be used to access dunder attributes.\n    - Ensure brackets/parentheses/braces are balanced and properly nested.\n    - Provide clear ParseError messages on rejection.\n    \"\"\"\n    if expr is None:\n        raise ParseError(\"No expression provided.\")\n\n    if len(expr) == 0:\n        raise ParseError(\"Expression is empty.\")\n\n    if len(expr) > DEFAULT_MAX_INPUT_LENGTH:\n        raise ParseError(f\"Input exceeds maximum length of {DEFAULT_MAX_INPUT_LENGTH} characters.\")\n\n    # Conservative allowed character set\n    allowed_chars = set(\"0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ +-*/^.,()[]{}=_\")\n    invalid_chars = sorted({c for c in expr if c not in allowed_chars})\n    if invalid_chars:\n        # Report up to a few invalid characters to avoid overly verbose messages\n        sample = \"\".join(invalid_chars[:10])\n        raise ParseError(f\"Expression contains disallowed characters: {sample}\")\n\n    # Disallow double-underscore patterns which can be abused to access internals\n    if \"__\" in expr:\n        raise ParseError(\"Expression contains disallowed pattern '__'.\")\n\n    # Lowercase version for substring checks\n    lower = expr.lower()\n\n    # Prohibited substrings/patterns that suggest attempts to execute code or access the environment\n    prohibited_substrings = [\n        \"import\",\n        \"os.\",\n        \"sys.\",\n        \"subprocess\",\n        \"socket\",\n        \"eval(\",\n        \"exec(\",\n        \"open(\",\n        \"compile(\",\n        \"globals(\",\n        \"locals(\",\n        \"`\",  # backticks\n        \";\",  # command separators\n        \"|\",  # pipes\n        \"&\",  # shell background/and\n        \"$\",  # shell/variables\n        \"<\",  # redirect/input\n        \">\",  # redirect/output\n        \"%\",  # formatting or modulo abuse\n        \"@\",  # decorators / attribute access\n        \"#\",  # comments\n        \"lambda \",\n    ]\n    for p in prohibited_substrings:\n        if p in lower:\n            raise ParseError(\"Expression contains disallowed substring or potentially dangerous token.\")\n\n    # Prevent obvious attempts to perform assignments or comparisons outside mathematical intent\n    # e.g., 'a = 1' or 'a==b' are not supported in this evaluator\n    if \"=\" in expr and \"==\" not in expr:\n        # If '=' present, it's likely unintended; require it to appear only in equality comparisons '=='\n        # But keep '=' allowed historically; block single '=' to avoid assignment attempts\n        raise ParseError(\"Single '=' assignments are not allowed in expressions.\")\n\n    if \"==\" in expr:\n        raise ParseError(\"'==' comparison operator is not allowed in expressions.\")\n\n    # Basic bracket/parentheses/braces balance and nesting check\n    pairs = {\")\": \"(\", \"]\": \"[\", \"}\": \"{\"}\n    opening = set(pairs.values())\n    stack: List[str] = []\n    for ch in expr:\n        if ch in opening:\n            stack.append(ch)\n        elif ch in pairs:\n            if not stack or stack[-1] != pairs[ch]:\n                raise ParseError(\"Mismatched or unbalanced parentheses/brackets/braces in expression.\")\n            stack.pop()\n    if stack:\n        raise ParseError(\"Mismatched or unbalanced parentheses/brackets/braces in expression.\")\n\n    # If we reach here, the expression passes the conservative checks\n    return True\n\n\ndef _normalize_raw(expr: str) -> str:\n    \"\"\"\n    Basic normalization:\n    - trim whitespace\n    - replace caret '^' with '**'\n    - collapse multiple spaces\n    - replace aliases like 'ln' to 'log' handled in local dict as well\n    \"\"\"\n    s = expr.strip()\n    s = s.replace(\"^\", \"**\")\n    s = re.sub(r\"\\s+\", \" \", s)\n    return s\n\n\ndef _ast_depth(expr: Expr) -> int:\n    \"\"\"\n    Compute depth of sympy expression tree.\n    \"\"\"\n    if not expr.args:\n        return 1\n    return 1 + max((_ast_depth(a) for a in expr.args), default=0)\n\n\ndef _node_count(expr: Expr) -> int:\n    \"\"\"\n    Count nodes in expression tree.\n    \"\"\"\n    count = 0\n    for _ in preorder_traversal(expr):\n        count += 1\n    return count\n\n\ndef _collect_tokens(expr: Expr) -> List[str]:\n    \"\"\"\n    Traverse the expression and return a list of tokens (operators, function names, literals, symbols).\n    \"\"\"\n    tokens = []\n\n    for node in preorder_traversal(expr):\n        # function or operator\n        if isinstance(node, Function):\n            tokens.append(str(type(node).__name__))\n        elif isinstance(node, Expr):\n            # numbers\n            if node.is_Number:\n                tokens.append(str(node))\n            elif node.is_Symbol:\n                tokens.append(str(node))\n            else:\n                # other expression nodes: use class name\n                tokens.append(node.func.__name__)\n        else:\n            tokens.append(str(node))\n    # Deduplicate preserving order roughly\n    seen = set()\n    out = []\n    for t in tokens:\n        if t not in seen:\n            out.append(t)\n            seen.add(t)\n    return out\n\n\ndef parse_expression(\n    expression: str,\n    max_length: int = DEFAULT_MAX_INPUT_LENGTH,\n    ast_depth_limit: int = DEFAULT_AST_DEPTH_LIMIT,\n) -> Dict[str, Any]:\n    \"\"\"\n    Parse and normalize an input expression string safely.\n\n    Returns dict:\n    - normalized: normalized expression string\n    - ast: a simple representation (string)\n    - tokens: list of tokens\n    - depth: ast depth\n    - node_count: node count\n    \"\"\"\n    if expression is None:\n        raise ParseError(\"No expression provided.\")\n\n    if len(expression) > max_length:\n        raise ParseError(f\"Input exceeds maximum length of {max_length} characters.\")\n\n    _check_allowed_chars(expression)\n\n    normalized_raw = _normalize_raw(expression)\n\n    try:\n        expr = parse_expr(\n            normalized_raw,\n            local_dict=LOCAL_DICT,\n            transformations=TRANSFORMATIONS,\n            evaluate=False,\n        )\n    except SympifyError as e:\n        raise ParseError(\"Failed to parse expression.\", details=str(e))\n    except Exception as e:\n        raise ParseError(\"Failed to parse expression.\", details=str(e))\n\n    depth = _ast_depth(expr)\n    if depth > ast_depth_limit:\n        raise ParseError(\"Expression AST depth exceeds allowed limit.\", details={\"depth\": depth})\n\n    node_count = _node_count(expr)\n    tokens = _collect_tokens(expr)\n\n    # Normalized string representation\n    normalized_str = str(expr)\n\n    return {\n        \"normalized\": normalized_str,\n        \"ast\": repr(expr),\n        \"tokens\": tokens,\n        \"depth\": depth,\n        \"node_count\": node_count,\n        \"expr\": expr,\n    }\n\n\ndef _apply_angle_mode(expr: Expr, angle_mode: str) -> Expr:\n    \"\"\"\n    If angle_mode == 'degrees', convert trig arguments from degrees to radians:\n    e.g., sin(x) -> sin(pi*x/180)\n    Works for sin, cos, tan, asin, acos, atan.\n    \"\"\"\n    if angle_mode not in (\"radians\", \"degrees\"):\n        raise ValueError(\"angle_mode must be 'radians' or 'degrees'\")\n\n    if angle_mode == \"radians\":\n        return expr  # nothing to do\n\n    # angle_mode == \"degrees\"\n    from sympy import sin, cos, tan, asin, acos, atan, Mul, Rational\n\n    def _convert(node):\n        # Only modify function nodes\n        if node.func.__name__ in {\"sin\", \"cos\", \"tan\", \"asin\", \"acos\", \"atan\"}:\n            # node.args is a tuple of arguments; convert first argument\n            arg = node.args[0]\n            # pi/180 * arg\n            new_arg = (pi * arg) / Rational(180)\n            return node.func(new_arg)\n        return node\n\n    # Recursively replace\n    return expr.xreplace({}) .xreplace({}) if False else expr.replace(lambda e: isinstance(e, Expr) and e.func.__name__ in {\"sin\",\"cos\",\"tan\",\"asin\",\"acos\",\"atan\"}, lambda e: _convert(e))\n\n\ndef _perform_domain_checks(expr: Expr, complex_mode: bool = False):\n    \"\"\"\n    Perform lightweight domain checks: sqrt of negative, log of non-positive,\n    asin/acos ranges, basic division by zero if denominators are literal zeros.\n\n    Raises DomainError for violations.\n    \"\"\"\n    # Check for sqrt of negative literal\n    for node in preorder_traversal(expr):\n        # log checks\n        try:\n            name = node.func.__name__\n        except Exception:\n            name = None\n\n        # Check sqrt and log for simple literal issues\n        if name in {\"sqrt\"}:\n            # if argument is a literal number\n            arg = node.args[0]\n            if arg.is_Number:\n                try:\n                    # convert to float to check sign\n                    val = float(arg.evalf())\n                    if val < 0 and not complex_mode:\n                        raise DomainError(\"Square root of negative number not allowed in real mode.\")\n                except Exception:\n                    # skip if cannot decide\n                    pass\n        if name in {\"log\"}:\n            # log(x) where x <=0 is invalid for real log\n            arg = node.args[0]\n            if arg.is_Number:\n                try:\n                    val = float(arg.evalf())\n                    if val <= 0:\n                        raise DomainError(\"Logarithm of non-positive number is undefined for real logs.\")\n                except Exception:\n                    pass\n        if name in {\"asin\", \"acos\"}:\n            arg = node.args[0]\n            if arg.is_Number:\n                try:\n                    val = float(arg.evalf())\n                    if not (-1.0 <= val <= 1.0):\n                        raise DomainError(f\"{name} argument out of domain for real-valued result.\")\n                except Exception:\n                    pass\n\n    # Basic division by zero detection for literal denominators\n    # find Mul with denominator as 1/0 or Pow with negative exponent? Simpler: inspect Rational denominators\n    for node in preorder_traversal(expr):\n        # For Rationals or Floats, sympy handles, but we can catch explicit divisions like x/0\n        if node.func.__name__ == \"Mul\":\n            # check for explicit division factor with zero? Not reliable\n            pass\n    # Note: many domain errors are discovered at evaluation time.\n\n\ndef _format_numeric_result(val: Any, precision: int) -> str:\n    \"\"\"\n    Format numeric result to string with given decimal precision.\n    Uses sympy Float/str to preserve precision when possible.\n    \"\"\"\n    try:\n        if isinstance(val, Float):\n            s = str(val.evalf(precision))\n            return s\n        # For mpmath mpf or complex\n        if hasattr(val, \"as_real_imag\"):\n            # sympy complex\n            real, imag = val.as_real_imag()\n            if imag != 0:\n                return f\"{real.evalf(precision)} + {imag.evalf(precision)}*I\"\n            return str(real.evalf(precision))\n        # fallback to float formatting (may lose precision)\n        f = float(val)\n        fmt = f\"{{:.{precision}f}}\"\n        return fmt.format(f)\n    except Exception:\n        # final fallback\n        return str(val)\n\n\ndef evaluate_expression(\n    expression: str = None,\n    parsed_expr: Expr = None,\n    precision: int = DEFAULT_PRECISION,\n    angle_mode: str = \"radians\",\n    complex_mode: bool = False,\n    generate_steps: bool = False,\n) -> Dict[str, Any]:\n    \"\"\"\n    Evaluate an expression either from raw string (expression) or a parsed sympy Expr (parsed_expr).\n\n    Returns dict:\n    - result: stringified result\n    - result_type: 'numeric' | 'symbolic' | 'error'\n    - normalized: normalized expression string\n    - steps: list of steps (if generated) or None\n    - error_message: present if an error occurred\n    \"\"\"\n    # Validate input length early to avoid expensive operations on overly long inputs\n    if expression is not None and len(expression) > DEFAULT_MAX_INPUT_LENGTH:\n        raise ParseError(f\"Input exceeds maximum length of {DEFAULT_MAX_INPUT_LENGTH} characters.\")\n\n    if parsed_expr is None:\n        parsed = parse_expression(expression)\n        expr = parsed[\"expr\"]\n        normalized = parsed[\"normalized\"]\n        node_count = parsed[\"node_count\"]\n    else:\n        expr = parsed_expr\n        normalized = str(parsed_expr)\n        node_count = _node_count(parsed_expr)\n\n    # Apply angle mode adjustments\n    try:\n        expr_for_eval = _apply_angle_mode(expr, angle_mode)\n    except Exception as e:\n        raise EvaluationError(\"Failed to apply angle mode.\", details=str(e))\n\n    # Domain checks\n    try:\n        _perform_domain_checks(expr_for_eval, complex_mode=complex_mode)\n    except DomainError as de:\n        raise de\n\n    # Setup mpmath precision\n    try:\n        mp.dps = max(6, int(precision) + 2)  # set a few guard digits\n    except Exception:\n        mp.dps = max(6, DEFAULT_PRECISION)\n\n    # Try numeric evaluation if possible (no free symbols). If symbols exist, return symbolic form.\n    symbols = list(expr_for_eval.free_symbols)\n    if symbols:\n        # symbolic result\n        try:\n            # attempt simplification for nicer symbolic form\n            simplified = expr_for_eval\n            try:\n                simplified = expr_for_eval.simplify()\n            except Exception:\n                pass\n            result_str = str(simplified)\n            steps = None\n            if generate_steps and node_count <= MAX_STEP_NODES:\n                steps = _generate_minimal_steps_for_symbolic(expr_for_eval, simplified)\n            return {\n                \"result\": result_str,\n                \"result_type\": \"symbolic\",\n                \"normalized\": normalized,\n                \"steps\": steps,\n                \"error_message\": None,\n            }\n        except Exception as e:\n            raise EvaluationError(\"Failed to produce symbolic result.\", details=str(e))\n\n    # Numeric evaluation path\n    try:\n        # Use sympy.N to perform numeric evaluation with precision\n        numeric = expr_for_eval.evalf(n=precision)\n    except ZeroDivisionError:\n        raise DomainError(\"Division by zero encountered during evaluation.\")\n    except Exception as e:\n        # try a different approach via naive python eval of lambda of sympy expression (safe-ish)\n        try:\n            numeric = float(expr_for_eval.evalf())\n        except Exception:\n            raise EvaluationError(\"Failed to evaluate expression numerically.\", details=str(e))\n\n    # Check for complex result\n    try:\n        # sympy complex detection\n        if numeric.has(I) or (hasattr(numeric, \"as_real_imag\") and numeric.as_real_imag()[1] != 0):\n            if not complex_mode:\n                raise DomainError(\"Evaluation produced a complex result while complex_mode is disabled.\")\n    except Exception:\n        # some numeric types may not have .has; fallback to string check\n        s_num = str(numeric)\n        if \"I\" in s_num and not complex_mode:\n            raise DomainError(\"Evaluation produced a complex result while complex_mode is disabled.\")\n\n    # Format result\n    result_str = _format_numeric_result(numeric, precision)\n\n    steps = None\n    if generate_steps and node_count <= MAX_STEP_NODES:\n        steps = _generate_minimal_steps_for_numeric(expr_for_eval, result_str, precision)\n\n    return {\n        \"result\": result_str,\n        \"result_type\": \"numeric\",\n        \"normalized\": normalized,\n        \"steps\": steps,\n        \"error_message\": None,\n    }\n\n\ndef _generate_minimal_steps_for_symbolic(original_expr: Expr, simplified_expr: Expr) -> List[str]:\n    \"\"\"\n    Very small scaffolded steps for symbolic expressions.\n    \"\"\"\n    steps = []\n    steps.append(f\"Parsed expression: {str(original_expr)}\")\n    if str(simplified_expr) != str(original_expr):\n        steps.append(f\"Simplified to: {str(simplified_expr)}\")\n    else:\n        steps.append(\"Expression is already in simplified/symbolic form.\")\n    steps.append(\"Returned symbolic expression; numeric evaluation was not performed since variables are present.\")\n    return steps\n\n\ndef _generate_minimal_steps_for_numeric(expr: Expr, result_str: str, precision: int) -> List[str]:\n    \"\"\"\n    Minimal numeric evaluation steps: show normalized form and the numeric result.\n    Real step-by-step symbolic algebra is out of scope here; we provide lightweight provenance.\n    \"\"\"\n    steps = []\n    steps.append(f\"Normalized expression: {str(expr)}\")\n    steps.append(f\"Evaluated numerically with precision={precision} -> {result_str}\")\n    steps.append(\"Note: Detailed algebraic steps are not available for this expression in the current worker.\")\n    return steps\n\n\ndef get_supported_functions() -> List[Dict[str, Any]]:\n    \"\"\"\n    Return a list of supported functions/operators with notes for the /functions endpoint.\n    \"\"\"\n    out = []\n    for name, target in _SUPPORTED_FUNCTIONS.items():\n        aliases = []\n        if name == \"ln\":\n            aliases = [\"ln -> log\"]\n        domain = _FUNCTION_DOMAIN_NOTES.get(name, \"\")\n        example = f\"{name}(x)\" if name not in {\"ln\"} else \"ln(x)  (alias of log(x))\"\n        out.append(\n            {\n                \"name\": name,\n                \"aliases\": aliases,\n                \"domain_notes\": domain,\n                \"example\": example,\n            }\n        )\n    # also include operators\n    operators = [\n        {\"name\": \"+\", \"description\": \"Addition\"},\n        {\"name\": \"-\", \"description\": \"Subtraction/Negation\"},\n        {\"name\": \"*\", \"description\": \"Multiplication\"},\n        {\"name\": \"/\", \"description\": \"Division\"},\n        {\"name\": \"**\", \"description\": \"Power (also ^ mapped to **)\"},\n    ]\n    return {\"functions\": out, \"operators\": operators}\n\n\n# Utility to create a small task id for queued tasks (if routes need it)\ndef new_task_id() -> str:\n    return str(uuid.uuid4())[:8]  # short id"}, {"path": "app/routes.py", "content": "from typing import List, Optional\nfrom uuid import uuid4\nimport re\n\nfrom fastapi import APIRouter, Depends, HTTPException, Query, status\nfrom sqlmodel import select\n\nfrom sqlalchemy import bindparam\n\nfrom app import auth, models, schemas, services\nfrom app.database import get_session\nfrom sqlmodel import Session\n\nrouter = APIRouter()\n\n# Reasonable maximum for parse max_length (per design default)\nMAX_PARSE_INPUT_LENGTH = 1000\n\n# Allowed client_id pattern: conservative subset of characters to avoid injection risks.\n# Only alphanumeric and hyphen, limited length.\n_CLIENT_ID_PATTERN = re.compile(r\"^[A-Za-z0-9\\-]{1,64}$\")\n\n\ndef _validate_client_id(client_id: Optional[str]) -> Optional[str]:\n    \"\"\"\n    Validate and sanitize client_id to avoid injection risks.\n    Accept only a conservative set of characters and reasonable length.\n    Returns the original client_id if valid, otherwise raises HTTPException.\n    \"\"\"\n    if client_id is None:\n        return None\n    if not isinstance(client_id, str):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail={\"error_code\": \"invalid_client_id\", \"message\": \"client_id must be a string\"},\n        )\n    if not _CLIENT_ID_PATTERN.match(client_id):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail={\n                \"error_code\": \"invalid_client_id\",\n                \"message\": \"client_id contains invalid characters or is too long; allowed: A-Z a-z 0-9 and hyphen (-), max length 64\",\n            },\n        )\n    return client_id\n\n\n@router.get(\"/health\", summary=\"Health check\")\ndef health(session: Session = Depends(get_session)):\n    \"\"\"\n    Health check endpoint. Verifies DB connectivity.\n    \"\"\"\n    try:\n        # simple lightweight DB probe\n        session.exec(select(1)).first()\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Database unreachable\", \"details\": str(e)},\n        )\n    return {\"status\": \"ok\", \"db\": True}\n\n\n@router.get(\"/functions\", response_model=schemas.FunctionsResponse, summary=\"List supported functions/operators\")\ndef list_functions():\n    \"\"\"\n    Return canonical list of supported functions/operators.\n    \"\"\"\n    funcs = services.get_supported_functions()\n    return {\"functions\": funcs}\n\n\n@router.post(\"/parse\", response_model=schemas.ParseResponse, summary=\"Parse expression into normalized form and tokens\")\ndef parse_expression(\n    payload: schemas.ParseRequest,\n    client_id: Optional[str] = Depends(auth.get_current_client),\n):\n    \"\"\"\n    Parse-only endpoint: returns normalized expression and safe AST/token list.\n    Validates payload.max_length to avoid excessively large values.\n    \"\"\"\n    # Validate max_length parameter if provided\n    max_length = payload.max_length\n    if max_length is not None:\n        try:\n            # ensure it's an int-like positive value and within allowed limit\n            if int(max_length) <= 0:\n                raise ValueError(\"max_length must be a positive integer\")\n        except Exception:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail={\"error_code\": \"invalid_parameter\", \"message\": \"max_length must be a positive integer\"},\n            )\n        if max_length > MAX_PARSE_INPUT_LENGTH:\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail={\n                    \"error_code\": \"max_length_exceeded\",\n                    \"message\": f\"max_length cannot exceed {MAX_PARSE_INPUT_LENGTH}\",\n                },\n            )\n\n    # validation/enforcement also happens in service\n    try:\n        parsed = services.parse_expression(payload.expression, max_length=payload.max_length)\n    except services.ParseError as e:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail={\"error_code\": \"parse_error\", \"message\": str(e)},\n        )\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail={\"error_code\": \"internal_error\", \"message\": \"Unexpected error during parsing\", \"details\": str(e)},\n        )\n\n    return schemas.ParseResponse(\n        raw_expression=payload.expression,\n        normalized_expression=parsed.get(\"normalized\"),\n        ast=parsed.get(\"ast_tokens\", []),\n    )\n\n\n@router.post(\"/evaluate\", response_model=schemas.EvaluateResponse, summary=\"Parse and evaluate an expression (sync)\")\ndef evaluate(\n    payload: schemas.EvaluateRequest,\n    session: Session = Depends(get_session),\n    client_id: Optional[str] = Depends(auth.get_current_client),\n):\n    \"\"\"\n    Evaluate expression synchronously (when possible). Persists a Calculation record.\n    \"\"\"\n    # sanitize client_id early\n    client_id = _validate_client_id(client_id)\n\n    try:\n        result = services.evaluate_expression(\n            payload.expression,\n            precision=payload.precision,\n            angle_mode=payload.angle_mode,\n            show_steps=payload.show_steps,\n            complex_mode=payload.complex_mode,\n            timeout_seconds=payload.timeout_seconds,\n        )\n    except services.ValidationError as e:\n        # Provide a clearer, structured response for validation/semantic errors\n        raise HTTPException(\n            status_code=status.HTTP_422_UNPROCESSABLE_ENTITY,\n            detail={\"error_code\": \"validation_error\", \"message\": str(e)},\n        )\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail={\"error_code\": \"internal_error\", \"message\": \"Unexpected error during evaluation\", \"details\": str(e)},\n        )\n\n    # Persist calculation record (successful or error)\n    calc_id = str(uuid4())\n    calc = models.Calculation(\n        id=calc_id,\n        expression=payload.expression,\n        normalized_expression=result.get(\"normalized_expression\") or result.get(\"normalized\") or \"\",\n        result=result.get(\"result\") if result.get(\"result\") is not None else \"\",\n        result_type=result.get(\"result_type\", \"error\"),\n        error_message=result.get(\"error_message\"),\n        precision=payload.precision,\n        angle_mode=payload.angle_mode,\n        steps=result.get(\"steps\") or [],\n        client_id=client_id,\n    )\n\n    try:\n        session.add(calc)\n        session.commit()\n        session.refresh(calc)\n    except Exception as e:\n        # If persistence fails, return a service-unavailable error rather than crash\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to persist calculation\", \"details\": str(e)},\n        )\n\n    # Shape response\n    if result.get(\"queued\"):\n        return schemas.EvaluateResponse(\n            id=calc_id,\n            normalized_expression=calc.normalized_expression,\n            result=calc.result,\n            result_type=calc.result_type,\n            error_message=calc.error_message,\n            steps=calc.steps,\n            queued=True,\n            task_id=result.get(\"task_id\"),\n        )\n\n    return schemas.EvaluateResponse(\n        id=calc_id,\n        normalized_expression=calc.normalized_expression,\n        result=calc.result,\n        result_type=calc.result_type,\n        error_message=calc.error_message,\n        steps=calc.steps,\n        queued=False,\n        task_id=None,\n    )\n\n\n@router.get(\"/examples\", response_model=schemas.ExampleListResponse, summary=\"List example problems\")\ndef list_examples(\n    limit: int = Query(20, gt=0, le=100),\n    offset: int = Query(0, ge=0),\n    session: Session = Depends(get_session),\n):\n    \"\"\"\n    Return curated example problems with pagination.\n    \"\"\"\n    statement = select(models.ExampleProblem).offset(offset).limit(limit)\n    try:\n        examples = session.exec(statement).all()\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to fetch examples\", \"details\": str(e)},\n        )\n    return schemas.ExampleListResponse(items=[schemas.ExampleRead.from_orm(e) for e in examples], limit=limit, offset=offset)\n\n\n@router.get(\"/examples/{example_id}\", response_model=schemas.ExampleRead, summary=\"Get an example problem by id\")\ndef get_example(example_id: str, session: Session = Depends(get_session)):\n    try:\n        example = session.get(models.ExampleProblem, example_id)\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to fetch example\", \"details\": str(e)},\n        )\n    if not example:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"error_code\": \"not_found\", \"message\": \"Example not found\"})\n    return schemas.ExampleRead.from_orm(example)\n\n\n@router.get(\"/calculations\", response_model=schemas.CalculationListResponse, summary=\"List recent calculations\")\ndef list_calculations(\n    limit: int = Query(20, gt=0, le=100),\n    offset: int = Query(0, ge=0),\n    session: Session = Depends(get_session),\n    client_id: Optional[str] = Depends(auth.get_current_client),\n):\n    \"\"\"\n    List calculations. If authenticated client_id is provided, returns that client's history; otherwise returns global recent calculations.\n    Uses parameterized queries to avoid injection risk when filtering by client_id.\n    \"\"\"\n    # sanitize client_id before use in query parameters\n    client_id = _validate_client_id(client_id)\n\n    base_stmt = select(models.Calculation).order_by(models.Calculation.created_at.desc()).offset(offset).limit(limit)\n    try:\n        if client_id:\n            # Use a bound parameter for client_id to ensure parameterization\n            stmt = base_stmt.where(models.Calculation.client_id == bindparam(\"client_id\"))\n            results = session.exec(stmt.params(client_id=client_id)).all()\n        else:\n            results = session.exec(base_stmt).all()\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to fetch calculations\", \"details\": str(e)},\n        )\n\n    items = [schemas.CalculationRead.from_orm(c) for c in results]\n    return schemas.CalculationListResponse(items=items, limit=limit, offset=offset)\n\n\n@router.get(\"/calculations/{calc_id}\", response_model=schemas.CalculationRead, summary=\"Get a calculation by id\")\ndef get_calculation(calc_id: str, session: Session = Depends(get_session), client_id: Optional[str] = Depends(auth.get_current_client)):\n    client_id = _validate_client_id(client_id)\n    try:\n        calc = session.get(models.Calculation, calc_id)\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to fetch calculation\", \"details\": str(e)},\n        )\n    if not calc:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"error_code\": \"not_found\", \"message\": \"Calculation not found\"})\n    # If client_id present, enforce access control\n    if client_id and calc.client_id and calc.client_id != client_id:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"error_code\": \"not_found\", \"message\": \"Calculation not found\"})\n    return schemas.CalculationRead.from_orm(calc)\n\n\n@router.delete(\"/calculations/{calc_id}\", status_code=status.HTTP_204_NO_CONTENT, summary=\"Delete a calculation\")\ndef delete_calculation(calc_id: str, session: Session = Depends(get_session), client_id: Optional[str] = Depends(auth.get_current_client)):\n    client_id = _validate_client_id(client_id)\n    try:\n        calc = session.get(models.Calculation, calc_id)\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to fetch calculation\", \"details\": str(e)},\n        )\n    if not calc:\n        raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail={\"error_code\": \"not_found\", \"message\": \"Calculation not found\"})\n    if client_id and calc.client_id and calc.client_id != client_id:\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail={\"error_code\": \"forbidden\", \"message\": \"Not allowed to delete this calculation\"})\n    # Perform hard delete; models may support soft-delete in future\n    try:\n        session.delete(calc)\n        session.commit()\n    except Exception as e:\n        raise HTTPException(\n            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,\n            detail={\"error_code\": \"db_unavailable\", \"message\": \"Failed to delete calculation\", \"details\": str(e)},\n        )\n    return None"}, {"path": "app/auth.py", "content": "from datetime import datetime, timedelta\nfrom typing import Optional, Dict, Any\n\nimport os\nimport json\nimport base64\nfrom pathlib import Path\n\nfrom fastapi import Depends, HTTPException, status, Header\nfrom fastapi.security import OAuth2PasswordBearer\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\n\n# --- Configuration ---\n# SECRET_KEY must be provided via one of the secure channels below.\n# Do NOT hardcode secrets in source. For production, use a secrets manager and inject into the environment.\n\n# Allow explicit override of secret/password strength checks (must be set deliberately).\n_ALLOW_WEAK_SECRET = str(os.getenv(\"ALLOW_WEAK_SECRET\", \"0\")).lower() in (\"1\", \"true\", \"yes\")\n_ALLOW_WEAK_DEMO_PASSWORD = str(os.getenv(\"ALLOW_WEAK_DEMO_PASSWORD\", \"0\")).lower() in (\"1\", \"true\", \"yes\")\n\n\ndef _is_strong_secret(s: str) -> bool:\n    \"\"\"\n    Basic entropy heuristics to ensure SECRET_KEY is not trivially weak.\n    Requirements:\n      - minimum length: 32 characters\n      - at least one lowercase, one uppercase, one digit, and one non-alphanumeric character\n    This is a conservative check to avoid accidental weak secrets in production.\n    \"\"\"\n    if not s or len(s) < 32:\n        return False\n    has_lower = any(c.islower() for c in s)\n    has_upper = any(c.isupper() for c in s)\n    has_digit = any(c.isdigit() for c in s)\n    has_symbol = any(not c.isalnum() for c in s)\n    return has_lower and has_upper and has_digit and has_symbol\n\n\ndef _is_strong_password(p: str) -> bool:\n    \"\"\"\n    Enforce a reasonable password policy for demo users.\n    Requirements:\n      - minimum length: 12 characters\n      - at least one lowercase, one uppercase, one digit, and one non-alphanumeric character\n    \"\"\"\n    if not p or len(p) < 12:\n        return False\n    has_lower = any(c.islower() for c in p)\n    has_upper = any(c.isupper() for c in p)\n    has_digit = any(c.isdigit() for c in p)\n    has_symbol = any(not c.isalnum() for c in p)\n    return has_lower and has_upper and has_digit and has_symbol\n\n\ndef _ensure_secret_strength(secret: str) -> None:\n    if _ALLOW_WEAK_SECRET:\n        return\n    if not _is_strong_secret(secret):\n        raise RuntimeError(\n            \"SECRET_KEY is present but does not meet strength requirements. \"\n            \"Provide a secret with at least 32 characters including upper/lower/digit/symbol. \"\n            \"If you intentionally want to allow a weaker secret (not recommended), set ALLOW_WEAK_SECRET=1.\"\n        )\n\n\ndef _retrieve_secret_key() -> str:\n    \"\"\"\n    Attempt to retrieve the SECRET_KEY from a set of secure locations, in order:\n    1. SECRET_KEY environment variable\n    2. SECRET_KEY_B64 environment variable (base64-encoded)\n    3. SECRET_KEY_FILE environment variable (path to file)\n    4. Docker-style secret files (e.g., /run/secrets/SECRET_KEY or /run/secrets/secret_key)\n    5. /etc/secrets/SECRET_KEY (common mounted secret path)\n    Raises RuntimeError if no valid non-empty secret is found or if the secret is considered weak.\n    \"\"\"\n    # 1. Direct env var\n    sk = os.getenv(\"SECRET_KEY\")\n    if sk and sk.strip():\n        sk_val = sk.strip()\n        _ensure_secret_strength(sk_val)\n        return sk_val\n\n    # 2. Base64-encoded env var\n    sk_b64 = os.getenv(\"SECRET_KEY_B64\")\n    if sk_b64 and sk_b64.strip():\n        try:\n            decoded = base64.b64decode(sk_b64.strip()).decode(\"utf-8\")\n            if decoded.strip():\n                _ensure_secret_strength(decoded.strip())\n                return decoded.strip()\n        except Exception as e:\n            raise RuntimeError(f\"Failed to decode SECRET_KEY_B64: {e}\")\n\n    # 3. File path provided via env var\n    sk_file = os.getenv(\"SECRET_KEY_FILE\")\n    if sk_file:\n        try:\n            p = Path(sk_file)\n            if p.is_file():\n                content = p.read_text(encoding=\"utf-8\").strip()\n                if content:\n                    _ensure_secret_strength(content)\n                    return content\n        except Exception as e:\n            raise RuntimeError(f\"Failed to read SECRET_KEY_FILE '{sk_file}': {e}\")\n\n    # 4. Common docker secret mount locations\n    possible_paths = [\n        Path(\"/run/secrets/SECRET_KEY\"),\n        Path(\"/run/secrets/secret_key\"),\n        Path(\"/run/secrets/secret\"),\n        Path(\"/etc/secrets/SECRET_KEY\"),\n    ]\n    for p in possible_paths:\n        try:\n            if p.is_file():\n                content = p.read_text(encoding=\"utf-8\").strip()\n                if content:\n                    _ensure_secret_strength(content)\n                    return content\n        except Exception:\n            # Silently continue to next path; do not expose filesystem errors here.\n            continue\n\n    # If we reach here, no secret was found.\n    raise RuntimeError(\n        \"SECRET_KEY not found. Set SECRET_KEY (or SECRET_KEY_B64 or SECRET_KEY_FILE), \"\n        \"or configure a secrets manager to inject the secret into the environment.\"\n    )\n\n\n# Lazily-loaded SECRET_KEY to avoid raising at import time if the application\n# is being validated in environments where secrets are provided later.\n_SECRET_KEY_CACHE: Optional[str] = None\n\n\ndef _get_secret_key() -> str:\n    global _SECRET_KEY_CACHE\n    if _SECRET_KEY_CACHE:\n        return _SECRET_KEY_CACHE\n    _SECRET_KEY_CACHE = _retrieve_secret_key()\n    return _SECRET_KEY_CACHE\n\n\nALGORITHM = \"HS256\"\nACCESS_TOKEN_EXPIRE_MINUTES = int(os.getenv(\"ACCESS_TOKEN_EXPIRE_MINUTES\", \"60\"))\n\n# API keys may be provided via:\n# - API_KEYS (plain comma-separated k:v pairs) [not recommended for production]\n# - API_KEYS_B64 (base64-encoded string of the same format)\n# - API_KEYS_FILE (path to a file containing either JSON mapping or k:v pairs, one per line)\n# For production, prefer injecting an encrypted secrets payload or using a secrets manager.\n_api_keys: Dict[str, str] = {}\n\n_api_keys_b64 = os.getenv(\"API_KEYS_B64\")\n_api_keys_raw = os.getenv(\"API_KEYS\")\n_api_keys_file = os.getenv(\"API_KEYS_FILE\")\n\n\ndef _load_api_keys_from_string(s: str) -> Dict[str, str]:\n    result: Dict[str, str] = {}\n    # Try JSON first\n    s_stripped = s.strip()\n    if not s_stripped:\n        return result\n    try:\n        parsed = json.loads(s_stripped)\n        if isinstance(parsed, dict):\n            # assume mapping of key -> client_id\n            for k, v in parsed.items():\n                result[str(k).strip()] = str(v).strip()\n            return result\n    except Exception:\n        pass\n    # Fallback to comma or newline separated k:client pairs\n    for pair in filter(None, (p.strip() for p in s_stripped.replace(\"\\n\", \",\").split(\",\"))):\n        if \":\" in pair:\n            k, v = pair.split(\":\", 1)\n            result[k.strip()] = v.strip()\n    return result\n\n\nif _api_keys_b64:\n    try:\n        decoded = base64.b64decode(_api_keys_b64).decode(\"utf-8\")\n        _api_keys.update(_load_api_keys_from_string(decoded))\n    except Exception as e:\n        raise RuntimeError(f\"Failed to decode API_KEYS_B64: {e}\")\nelif _api_keys_raw:\n    _api_keys.update(_load_api_keys_from_string(_api_keys_raw))\nelif _api_keys_file:\n    try:\n        with open(_api_keys_file, \"r\", encoding=\"utf-8\") as f:\n            content = f.read()\n        _api_keys.update(_load_api_keys_from_string(content))\n    except Exception as e:\n        raise RuntimeError(f\"Failed to read API_KEYS_FILE '{_api_keys_file}': {e}\")\n# If no API keys configured, _api_keys remains empty.\n# Authentication via API keys will simply fail, which is preferable to silently accepting a default insecure key.\n\n# --- Password hashing ---\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\n\n# OAuth2 scheme - tokenUrl should match the actual token route implemented by the app (e.g. /token)\noauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"/token\")\n\n\n# --- Fake user store for minimal token flow ---\n# This is intentionally minimal for the demo. Real deployments should use a user table.\n# To avoid hardcoded credentials in source, demo user(s) are populated only when the\n# appropriate environment variables are provided.\n_fake_users_db: Dict[str, Dict[str, Any]] = {}\n\n_demo_username = os.getenv(\"DEMO_USER\")\n_demo_password = os.getenv(\"DEMO_USER_PASSWORD\")\n_demo_fullname = os.getenv(\"DEMO_USER_FULLNAME\", \"Demo User\")\n\nif _demo_username and _demo_password:\n    # Validate demo password strength to avoid accidental weak demo accounts.\n    if not _is_strong_password(_demo_password) and not _ALLOW_WEAK_DEMO_PASSWORD:\n        raise RuntimeError(\n            \"DEMO_USER_PASSWORD does not meet the required strength policy. \"\n            \"Passwords must be at least 12 characters and include uppercase, lowercase, digits and symbols. \"\n            \"If this is intentional for a development environment, set ALLOW_WEAK_DEMO_PASSWORD=1 to override.\"\n        )\n    # Only create a demo user when credentials are explicitly provided via env vars.\n    _fake_users_db[_demo_username] = {\n        \"username\": _demo_username,\n        \"full_name\": _demo_fullname,\n        \"hashed_password\": pwd_context.hash(_demo_password),\n        \"disabled\": False,\n    }\n\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    return pwd_context.verify(plain_password, hashed_password)\n\n\ndef get_user(username: str) -> Optional[Dict[str, Any]]:\n    return _fake_users_db.get(username)\n\n\ndef authenticate_user(username: str, password: str) -> Optional[Dict[str, Any]]:\n    user = get_user(username)\n    if not user:\n        return None\n    if not verify_password(password, user[\"hashed_password\"]):\n        return None\n    return user\n\n\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None) -> str:\n    to_encode = data.copy()\n    expire = datetime.utcnow() + (expires_delta or timedelta(minutes=ACCESS_TOKEN_EXPIRE_MINUTES))\n    to_encode.update({\"exp\": expire})\n    secret = _get_secret_key()\n    encoded_jwt = jwt.encode(to_encode, secret, algorithm=ALGORITHM)\n    return encoded_jwt\n\n\n# --- Dependencies / helpers for routes ---\n\n\nasync def get_current_user(token: str = Depends(oauth2_scheme)) -> Dict[str, Any]:\n    \"\"\"\n    Dependency that extracts and validates a JWT access token and returns the user dict.\n    Raises 401 on invalid/expired token.\n    \"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    try:\n        payload = jwt.decode(token, _get_secret_key(), algorithms=[ALGORITHM])\n        username: Optional[str] = payload.get(\"sub\")\n        if username is None:\n            raise credentials_exception\n    except JWTError:\n        raise credentials_exception\n    user = get_user(username)\n    if user is None:\n        raise credentials_exception\n    if user.get(\"disabled\"):\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"User is disabled\")\n    return user\n\n\nasync def get_current_active_user(current_user: Dict[str, Any] = Depends(get_current_user)) -> Dict[str, Any]:\n    \"\"\"\n    Alias dependency ensuring the user is active; keeps layering for future checks.\n    \"\"\"\n    # Currently get_current_user already checks disabled flag, but keep this for extensibility.\n    if current_user.get(\"disabled\"):\n        raise HTTPException(status_code=status.HTTP_403_FORBIDDEN, detail=\"Inactive user\")\n    return current_user\n\n\ndef _verify_api_key_header(x_api_key: Optional[str]) -> str:\n    if not x_api_key:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Missing API key\",\n            headers={\"WWW-Authenticate\": \"API-Key\"},\n        )\n    client_id = _api_keys.get(x_api_key)\n    if not client_id:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Invalid API key\",\n            headers={\"WWW-Authenticate\": \"API-Key\"},\n        )\n    return client_id\n\n\nasync def get_client_id_from_api_key(x_api_key: Optional[str] = Header(None)) -> str:\n    \"\"\"\n    Dependency to extract a client id from an API key provided in the x-api-key header.\n    \"\"\"\n    return _verify_api_key_header(x_api_key)\n\n\nasync def get_current_client(\n    authorization: Optional[str] = Header(None),\n    x_api_key: Optional[str] = Header(None),\n) -> str:\n    \"\"\"\n    Flexible dependency which accepts either a Bearer token (JWT) or an x-api-key header.\n    Returns a client identifier (username for tokens, client_id for api-keys).\n    Raises 401 if neither provided or invalid.\n    \"\"\"\n    # Try token first if present\n    if authorization:\n        try:\n            scheme, _, token = authorization.partition(\" \")\n            if scheme.lower() == \"bearer\" and token:\n                payload = jwt.decode(token, _get_secret_key(), algorithms=[ALGORITHM])\n                username: Optional[str] = payload.get(\"sub\")\n                if username is None:\n                    raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid token\")\n                user = get_user(username)\n                if not user or user.get(\"disabled\"):\n                    raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid or disabled user\")\n                return username\n        except JWTError:\n            raise HTTPException(status_code=status.HTTP_401_UNAUTHORIZED, detail=\"Invalid token\")\n    # Fall back to API key\n    if x_api_key:\n        return _verify_api_key_header(x_api_key)\n    # Nothing provided\n    raise HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Not authenticated (provide Bearer token or x-api-key header)\",\n        headers={\"WWW-Authenticate\": \"Bearer, API-Key\"},\n    )\n\n\n# --- Utility to produce a token response payload used by /token route implemented elsewhere ---\ndef token_response_for_user(user: Dict[str, Any], expires_delta: Optional[timedelta] = None) -> Dict[str, Any]:\n    access_token = create_access_token(data={\"sub\": user[\"username\"]}, expires_delta=expires_delta)\n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}"}], "dependencies": ["fastapi", "sqlmodel", "uvicorn", "sympy", "mpmath", "python-jose[cryptography]", "passlib[bcrypt]"]}